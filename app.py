from fastapi import FastAPI, File, UploadFile
import numpy as np
import tensorflow.lite as tflite
from PIL import Image
import io
from rembg import remove  # rembg ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

app = FastAPI()

# 1. TFLite ëª¨ë¸ ë¡œë“œ
model_path = "final_model.tflite"
interpreter = tflite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# ğŸ“Œ 2. train_generator.class_indices ì‚¬ìš©
# ì‹¤ì œ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ class_indicesë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.
# ì˜ˆì‹œë¡œ ì•„ë˜ëŠ” í•™ìŠµ ì‹œ ì‚¬ìš©í•œ class_indicesì™€ ê°™ì€ í˜•íƒœë¡œ ì •ì˜í•œ ê²ƒì…ë‹ˆë‹¤.
# ì´ ë¶€ë¶„ì€ ì‹¤ì œ ëª¨ë¸ í•™ìŠµ ì‹œ train_generatorì—ì„œ class_indicesë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.

class_indices = {
    'ê°€ì§€ë³¶ìŒ': 0, 'ê°„ì¥ê²Œì¥': 1, 'ê°ˆë¹„êµ¬ì´': 2, 'ê°ˆë¹„ì°œ': 3, 'ê°ˆë¹„íƒ•': 4, 'ê°ˆì¹˜êµ¬ì´': 5, 'ê°ˆì¹˜ì¡°ë¦¼': 6, 'ê°ìì „': 7, 'ê°ìì¡°ë¦¼': 8, 'ê°ìì±„ë³¶ìŒ': 9, 'ê°ìíƒ•': 10, 'ê°“ê¹€ì¹˜': 11, 'ê±´ìƒˆìš°ë³¶ìŒ': 12, 'ê²½ë‹¨': 13, 'ê³„ë€êµ­': 14, 'ê³„ë€ë§ì´': 15, 'ê³„ë€ì°œ': 16, 'ê³„ë€í›„ë¼ì´': 17, 'ê³ ë“±ì–´êµ¬ì´': 18, 'ê³ ë“±ì–´ì¡°ë¦¼': 19, 'ê³ ì‚¬ë¦¬ë‚˜ë¬¼': 20, 'ê³ ì¶”ì¥ì§„ë¯¸ì±„ë³¶ìŒ': 21, 'ê³ ì¶”íŠ€ê¹€': 22, 'ê³°íƒ•_ì„¤ë íƒ•': 23, 'ê³±ì°½êµ¬ì´': 24, 'ê³±ì°½ì „ê³¨': 25, 'ê³¼ë©”ê¸°': 26, 'ê¹€ë°¥': 27, 'ê¹€ì¹˜ë³¶ìŒë°¥': 28, 'ê¹€ì¹˜ì „': 29, 'ê¹€ì¹˜ì°Œê°œ': 30, 'ê¹€ì¹˜ì°œ': 31, 'ê¹ë‘ê¸°': 32, 'ê¹»ìì¥ì•„ì°Œ': 33, 'ê¼¬ë§‰ì°œ': 34, 'ê½ì¹˜ì¡°ë¦¼': 35, 'ê½ˆë¦¬ê³ ì¶”ë¬´ì¹¨': 36, 'ê¿€ë–¡': 37, 'ë‚˜ë°•ê¹€ì¹˜': 38, 'ëˆ„ë£½ì§€': 39, 'ë‹­ê°ˆë¹„': 40, 'ë‹­ê³„ì¥': 41, 'ë‹­ë³¶ìŒíƒ•': 42, 'ë”ë•êµ¬ì´': 43, 'ë„ë¼ì§€ë¬´ì¹¨': 44, 'ë„í† ë¦¬ë¬µ': 45, 'ë™ê·¸ë‘ë•¡': 46, 'ë™íƒœì°Œê°œ': 47, 'ëœì¥ì°Œê°œ': 48, 'ë‘ë¶€ê¹€ì¹˜': 49, 'ë‘ë¶€ì¡°ë¦¼': 50, 'ë•…ì½©ì¡°ë¦¼': 51, 'ë–¡ê°ˆë¹„': 52, 'ë–¡êµ­_ë§Œë‘êµ­': 53, 'ë–¡ê¼¬ì¹˜': 54, 'ë–¡ë³¶ì´': 55, 'ë¼ë©´': 56, 'ë¼ë³¶ì´': 57, 'ë§‰êµ­ìˆ˜': 58, 'ë§Œë‘': 59, 'ë§¤ìš´íƒ•': 60, 'ë©ê²Œ': 61, 'ë©”ì¶”ë¦¬ì•Œì¥ì¡°ë¦¼': 62, 'ë©¸ì¹˜ë³¶ìŒ': 63, 'ë¬´êµ­': 64, 'ë¬´ìƒì±„': 65, 'ë¬¼ëƒ‰ë©´': 66, 'ë¬¼íšŒ': 67, 'ë¯¸ì—­êµ­': 68, 'ë¯¸ì—­ì¤„ê¸°ë³¶ìŒ': 69, 'ë°°ì¶”ê¹€ì¹˜': 70, 'ë°±ê¹€ì¹˜': 71, 'ë³´ìŒˆ': 72, 'ë¶€ì¶”ê¹€ì¹˜': 73, 'ë¶ì—‡êµ­': 74, 'ë¶ˆê³ ê¸°': 75, 'ë¹„ë¹”ëƒ‰ë©´': 76, 'ë¹„ë¹”ë°¥': 77, 'ì‚°ë‚™ì§€': 78, 'ì‚¼ê²¹ì‚´': 79, 'ì‚¼ê³„íƒ•': 80, 'ìƒˆìš°ë³¶ìŒë°¥': 81, 'ìƒˆìš°íŠ€ê¹€': 82, 'ìƒì„ ì „': 83, 'ì†Œì„¸ì§€ë³¶ìŒ': 84, 'ì†¡í¸': 85, 'ìˆ˜ìœ¡': 86, 'ìˆ˜ì •ê³¼': 87, 'ìˆ˜ì œë¹„': 88, 'ìˆ™ì£¼ë‚˜ë¬¼': 89, 'ìˆœëŒ€': 90, 'ìˆœë‘ë¶€ì°Œê°œ': 91, 'ì‹œê¸ˆì¹˜ë‚˜ë¬¼': 92, 'ì‹œë˜ê¸°êµ­': 93, 'ì‹í˜œ': 94, 'ì•Œë°¥': 95, 'ì• í˜¸ë°•ë³¶ìŒ': 96, 'ì•½ê³¼': 97, 'ì•½ì‹': 98, 'ì–‘ë…ê²Œì¥': 99, 'ì–‘ë…ì¹˜í‚¨': 100, 'ì–´ë¬µë³¶ìŒ': 101, 'ì—°ê·¼ì¡°ë¦¼': 102, 'ì—´ë¬´êµ­ìˆ˜': 103, 'ì—´ë¬´ê¹€ì¹˜': 104, 'ì˜¤ì´ì†Œë°•ì´': 105, 'ì˜¤ì§•ì–´ì±„ë³¶ìŒ': 106, 'ì˜¤ì§•ì–´íŠ€ê¹€': 107, 'ìš°ì—‰ì¡°ë¦¼': 108, 'ìœ ë¶€ì´ˆë°¥': 109, 'ìœ¡ê°œì¥': 110, 'ìœ¡íšŒ': 111, 'ì”ì¹˜êµ­ìˆ˜': 112, 'ì¡ê³¡ë°¥': 113, 'ì¡ì±„': 114, 'ì¥ì–´êµ¬ì´': 115, 'ì¥ì¡°ë¦¼': 116, 'ì „ë³µì£½': 117, 'ì “ê°ˆ': 118, 'ì œìœ¡ë³¶ìŒ': 119, 'ì¡°ê°œêµ¬ì´': 120, 'ì¡°ê¸°êµ¬ì´': 121, 'ì¡±ë°œ': 122, 'ì£¼ê¾¸ë¯¸ë³¶ìŒ': 123, 'ì£¼ë¨¹ë°¥': 124, 'ì§œì¥ë©´': 125, 'ì§¬ë½•': 126, 'ì«„ë©´': 127, 'ì°œë‹­': 128, 'ì´ê°ê¹€ì¹˜': 129, 'ì¶”ì–´íƒ•': 130, 'ì¹¼êµ­ìˆ˜': 131, 'ì½”ë‹¤ë¦¬ì¡°ë¦¼': 132, 'ì½©êµ­ìˆ˜': 133, 'ì½©ë‚˜ë¬¼êµ­': 134, 'ì½©ë‚˜ë¬¼ë¬´ì¹¨': 135, 'ì½©ìë°˜': 136, 'íŒŒê¹€ì¹˜': 137, 'íŒŒì „': 138, 'í¸ìœ¡': 139, 'í”¼ì': 140, 'í•œê³¼': 141, 'í•´ë¬¼ì°œ': 142, 'í˜¸ë°•ì „': 143, 'í˜¸ë°•ì£½': 144, 'í™ì–´ë¬´ì¹¨': 145, 'í™©íƒœêµ¬ì´': 146, 'íšŒë¬´ì¹¨': 147, 'í›„ë¼ì´ë“œì¹˜í‚¨': 148, 'í›ˆì œì˜¤ë¦¬': 149
}


classes = list(class_indices.keys())

# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image: Image.Image):
    image = image.resize((224, 224))  # ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶¤
    image = np.array(image, dtype=np.float32) / 255.0  # ì •ê·œí™”
    image = np.expand_dims(image, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return image

# 4. FastAPI ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    # 1) ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì½ê¸°
    input_bytes = await file.read()
    image = Image.open(io.BytesIO(input_bytes)).convert("RGB")

    # 2) rembgë¡œ ë°°ê²½ ì œê±° (ë°°ê²½ íˆ¬ëª… ì²˜ë¦¬)
    img_no_bg = remove(image)

    # 3) rembg ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ RGB ëª¨ë“œë¡œ ë³€í™˜ (rembgëŠ” RGBA ë°˜í™˜)
    img_no_bg = img_no_bg.convert("RGB")

    # 4) ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    input_data = preprocess_image(img_no_bg)

    # 5) ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()
    output_data = interpreter.get_tensor(output_details[0]['index'])

    # 6) ê²°ê³¼ ì²˜ë¦¬
    predicted_index = np.argmax(output_data)
    predicted_class = classes[predicted_index]
    confidence = float(output_data[0][predicted_index])
    predicted_id = class_indices[predicted_class]

    return {"id": predicted_id, "class": predicted_class, "confidence": confidence}
