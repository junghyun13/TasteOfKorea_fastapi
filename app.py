from fastapi import FastAPI, File, UploadFile
import numpy as np
import tensorflow.lite as tflite
from PIL import Image
import io

app = FastAPI()

# ğŸ“Œ 1. .tflite ëª¨ë¸ ë¡œë“œ
model_path = "final_model.tflite"
interpreter = tflite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# ì…ë ¥ ë° ì¶œë ¥ í…ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# âœ… ë””ë²„ê¹…ìš© ì…ë ¥ í…ì„œ shape ì¶œë ¥
print("ğŸ‘‰ expected input shape from model:", input_details[0]['shape'])  # ì˜ˆ: (1, 3, 299, 299)

# ğŸ“Œ 2. train_generator.class_indices ì‚¬ìš©
# ì‹¤ì œ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ class_indicesë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.
# ì˜ˆì‹œë¡œ ì•„ë˜ëŠ” í•™ìŠµ ì‹œ ì‚¬ìš©í•œ class_indicesì™€ ê°™ì€ í˜•íƒœë¡œ ì •ì˜í•œ ê²ƒì…ë‹ˆë‹¤.
# ì´ ë¶€ë¶„ì€ ì‹¤ì œ ëª¨ë¸ í•™ìŠµ ì‹œ train_generatorì—ì„œ class_indicesë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.

class_indices = {
'ê°€ì§€ë³¶ìŒ': 0,

'ê°„ì¥ê²Œì¥': 1,

'ê°ˆë¹„íƒ•': 2,

'ê°ˆì¹˜êµ¬ì´': 3,

'ê°ìì¡°ë¦¼': 4,

'ê°ìì±„ë³¶ìŒ': 5,

'ê°ìíƒ•': 6,

'ê°“ê¹€ì¹˜': 7,

'ê±´ìƒˆìš°ë³¶ìŒ': 8,

'ê²½ë‹¨': 9,

'ê³„ë€êµ­': 10,

'ê³„ë€ë§ì´': 11,

'ê³„ë€ì°œ': 12,

'ê³ ë“±ì–´êµ¬ì´': 13,

'ê³ ì‚¬ë¦¬ë‚˜ë¬¼': 14,

'ê³ ì¶”íŠ€ê¹€': 15,

'ê³°íƒ•_ì„¤ë íƒ•': 16,

'ê³±ì°½êµ¬ì´': 17,

'ê³¼ë©”ê¸°': 18,

'ê¹€ë°¥': 19,

'ê¹€ì¹˜ë³¶ìŒë°¥': 20,

'ê¹€ì¹˜ì „': 21,

'ê¹€ì¹˜ì°Œê°œ': 22,

'ê¹ë‘ê¸°': 23,

'ê¹»ìì¥ì•„ì°Œ': 24,

'ê¼¬ë§‰ì°œ': 25,

'ê½ˆë¦¬ê³ ì¶”ë¬´ì¹¨': 26,

'ê¿€ë–¡': 27,

'ë‚˜ë°•ê¹€ì¹˜': 28,

'ëˆ„ë£½ì§€': 29,

'ë‹­ê°ˆë¹„': 30,

'ë„í† ë¦¬ë¬µ': 31,

'ë™ê·¸ë‘ë•¡': 32,

'ëœì¥ì°Œê°œ': 33,

'ë‘ë¶€ê¹€ì¹˜': 34,

'ë‘ë¶€ì¡°ë¦¼': 35,

'ë•…ì½©ì¡°ë¦¼': 36,

'ë–¡ê°ˆë¹„': 37,

'ë–¡êµ­_ë§Œë‘êµ­': 38,

'ë–¡ê¼¬ì¹˜': 39,

'ë–¡ë³¶ì´': 40,

'ë¼ë©´': 41,

'ë¼ë³¶ì´': 42,

'ë§‰êµ­ìˆ˜': 43,

'ë§Œë‘': 44,

'ë©ê²Œ': 45,

'ë©”ì¶”ë¦¬ì•Œì¥ì¡°ë¦¼': 46,

'ë©¸ì¹˜ë³¶ìŒ': 47,

'ë¬´êµ­': 48,

'ë¬´ìƒì±„': 49,

'ë¬¼ëƒ‰ë©´': 50,

'ë¬¼íšŒ': 51,

'ë¯¸ì—­êµ­': 52,

'ë¯¸ì—­ì¤„ê¸°ë³¶ìŒ': 53,

'ë°°ì¶”ê¹€ì¹˜': 54,

'ë°±ê¹€ì¹˜': 55,

'ë³´ìŒˆ': 56,

'ë¶€ì¶”ê¹€ì¹˜': 57,

'ë¶ˆê³ ê¸°': 58,

'ë¹„ë¹”ëƒ‰ë©´': 59,

'ë¹„ë¹”ë°¥': 60,

'ì‚°ë‚™ì§€': 61,

'ì‚¼ê²¹ì‚´': 62,

'ì‚¼ê³„íƒ•': 63,

'ìƒˆìš°ë³¶ìŒë°¥': 64,

'ìƒˆìš°íŠ€ê¹€': 65,

'ìƒì„ ì¡°ë¦¼': 66,

'ì†Œì„¸ì§€ë³¶ìŒ': 67,

'ì†¡í¸': 68,

'ìˆ˜ì •ê³¼': 69,

'ìˆ™ì£¼ë‚˜ë¬¼': 70,

'ìˆœëŒ€': 71,

'ìˆœë‘ë¶€ì°Œê°œ': 72,

'ì‹œê¸ˆì¹˜ë‚˜ë¬¼': 73,

'ì‹œë˜ê¸°êµ­': 74,

'ì‹í˜œ': 75,

'ì• í˜¸ë°•ë³¶ìŒ': 76,

'ì•½ê³¼': 77,

'ì•½ì‹': 78,

'ì–‘ë…ê²Œì¥': 79,

'ì–‘ë…ì¹˜í‚¨': 80,

'ì–´ë¬µë³¶ìŒ': 81,

'ì—°ê·¼ì¡°ë¦¼': 82,

'ì—´ë¬´êµ­ìˆ˜': 83,

'ì—´ë¬´ê¹€ì¹˜': 84,

'ì˜¤ì´ì†Œë°•ì´': 85,

'ì˜¤ì§•ì–´ì±„ë³¶ìŒ': 86,

'ìš°ì—‰ì¡°ë¦¼': 87,

'ìœ ë¶€ì´ˆë°¥': 88,

'ìœ¡ê°œì¥': 89,

'ìœ¡íšŒ': 90,

'ì”ì¹˜êµ­ìˆ˜': 91,

'ì¡ê³¡ë°¥': 92,

'ì¡ì±„': 93,

'ì¥ì–´êµ¬ì´': 94,

'ì¥ì¡°ë¦¼': 95,

'ì „ë³µì£½': 96,

'ì œìœ¡ë³¶ìŒ': 97,

'ì¡°ê°œêµ¬ì´': 98,

'ì¡°ê¸°êµ¬ì´': 99,

'ì¡±ë°œ': 100,

'ì£¼ê¾¸ë¯¸ë³¶ìŒ': 101,

'ì§œì¥ë©´': 102,

'ì§¬ë½•': 103,

'ì«„ë©´': 104,

'ì°œë‹­': 105,

'ì´ê°ê¹€ì¹˜': 106,

'ì¶”ì–´íƒ•': 107,

'ì¹¼êµ­ìˆ˜': 108,

'ì½©êµ­ìˆ˜': 109,

'ì½©ë‚˜ë¬¼êµ­': 110,

'ì½©ë‚˜ë¬¼ë¬´ì¹¨': 111,

'ì½©ìë°˜': 112,

'íŒŒê¹€ì¹˜': 113,

'íŒŒì „': 114,

'í”¼ì': 115,

'í•œê³¼': 116,

'í•´ë¬¼ì°œ': 117,

'í˜¸ë°•ì „': 118,

'í˜¸ë°•ì£½': 119,

'í™©íƒœêµ¬ì´': 120,

'í›„ë¼ì´ë“œì¹˜í‚¨': 121,

'í›ˆì œì˜¤ë¦¬': 122}


classes = list(class_indices.keys())

# ğŸ“Œ 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image: Image.Image):
    # âœ… ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í¬ê¸° ì¶”ì¶œ
    expected_shape = input_details[0]['shape']
    if len(expected_shape) == 4:
        if expected_shape[1] == 3:
            input_height = expected_shape[2]
            input_width = expected_shape[3]
        else:
            input_height = expected_shape[1]
            input_width = expected_shape[2]
    else:
        input_height = 224
        input_width = 224



    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    image = image.resize((input_width, input_height))
    image = np.array(image, dtype=np.float32) / 255.0

    if image.ndim == 2:
        image = np.stack((image,) * 3, axis=-1)
    elif image.shape[-1] == 4:
        image = image[..., :3]

    # ì±„ë„ ìˆœì„œ ë³€ê²½ (HWC â†’ CHW)
    image = np.transpose(image, (2, 0, 1))
    image = np.expand_dims(image, axis=0)

 

    return image.astype(np.float32)

# ğŸ“Œ 4. ì˜ˆì¸¡ API
@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    image = Image.open(io.BytesIO(await file.read())).convert("RGB")
    input_data = preprocess_image(image)

    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    output_data = interpreter.get_tensor(output_details[0]['index'])

    predicted_index = int(np.argmax(output_data))
    predicted_class = classes[predicted_index]
    confidence = float(output_data[0][predicted_index])
    predicted_id = class_indices[predicted_class]

    return {
        "id": predicted_id,
        "class": predicted_class,
        "confidence": confidence
    }